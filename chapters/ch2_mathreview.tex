\chapter{Math Review}
Throughout economics, we use mathematics to formalize our thinking and to make sure that our chain of reasoning makes sense. In this chapter, we provide a review of the mathematics that will be necessary for this course.

Because economics focuses primarily on optimizing agents on the margin, we extensively use multivariable calculus, for both constrained and unconstrained optimization. In this chapter, we review the basic concepts of differentiation, constrained and unconstrained optimization, as well as some notation that will be used throughout the course. 

\section{Differentiation}
\subsection*{Single variable differentiation}
Perhaps the most important mathematical concept for this course is that of the derivative. Suppose we have some function, $f: \R \to \R$, where $\R$ is the set of real numbers and the above notation tells us that the function $f$ takes a real number as an input and returns a real number. Formally, the \vocab{derivative} of $f$ at a point $x$ is defined as,
\begin{align*}
    \frac{df}{dx}(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{dh}
\end{align*}
Informally, the derivative $\frac{df}{dx}(x)$ represents how much the value of $f$ changes for a very small increase in the value of $x$. Graphically, the derivative is the slope of the line tangent to $f$ at $x$. The derivative, $\frac{df}{dx}$ is a function of $x$, but we will often omit the arguments to the function and just write $\frac{df}{dx}$. 

Notice that the definition of the derivative assumes that the limit exists. For the most part in this course, we assume that $f$ is \vocab{smooth}, which means that we can differentiate $f$ infinitely many times. $\frac{df}{dx}$ is also called the \vocab{first derivative} of $f$, because it is the result of differentiating $f$ once. To get a higher order derivative, we simply differentiate the derivative. $\frac{d^2f}{dx^2}$ is the \vocab{second derivative} of $f$, and is found by taking the derivative of $\frac{df}{dx}$, and higher order derivatives are found similarly. The notation for the $n$th derivative of $f$ is given by $\frac{d^nf}{dx^n}(x)$. The second derivative, $\frac{d^2f}{dx^2}$, is of particular importance in economics because it represents the concavity/convexity of a function. If $\frac{d^2f}{dx^2} > 0$, then we say that $f$ is \vocab{convex} at $x$, and if $\frac{d^2f}{dx^2}(x) < 0$, then we say that $f$ is \vocab{concave} at $x$. If $\frac{d^2f}{dx^2}(x) < 0$ for all $x$, then $f$ is \vocab{globally concave}, and if $\frac{df^2}{dx^2}(x) > 0$ for all $x$, then $f$ is \vocab{globally convex}. We will very rarely need to deal with cases where the derivative is of an order higher than 2.

So far, the notation we have used for the derivative is called \vocab{Leibnitz notation}. This notation treats the derivative as the operator, $\frac{d}{dx}$ applied to the function $f$ at the point $x$. Hence, the second derivative is
\begin{align*}
    \frac{d^2}{dx^2} f(x) = \frac{d^2f}{dx^2}(x)
\end{align*}
However, occasionally in this course, we will use a different notation for derivative out of convenience, known as \vocab{Lagrange notation}, where the first derivative of $f$ with respect to $x$ is written as
\begin{align*}
    f'(x) = \frac{df}{dx}(x)
\end{align*}
The second derivative is written as
\begin{align*}
    f''(x) = \frac{d^2f}{dx^2}
\end{align*}
And in general, the $n$th derivative is written as
\begin{align*}
    f^{(n)}(x) = \frac{d^nf}{dx^n}(x)
\end{align*}
Throughout this textbook, we will standardize to using Leibnitz notation, but Lagrange notation may occasionally be used in the course, and it should be noted that they are the same. 

\subsubsection*{Differentiation rules}
We assume knowledge of some basic rules and properties of differentation. We list some of the most important ones here:
\begin{description}
    \item[Power rule] For a constant $\alpha$, 
    \begin{align*}
        \frac{d}{dx}(x^\alpha) = \alpha x^{\alpha - 1}
    \end{align*}
    \item[Linearity] For $\alpha, \beta \in \R$, and functions $f, g$, we have
    \begin{align*}
        \frac{d}{dx} (\alpha f(x) + \beta g(x)) = \alpha \frac{df}{dx}(x) + \beta \frac{dg}{dx}(x) = \alpha f'(x) + \beta g'(x)
    \end{align*} 
    \item[Product Rule] For functions $f, g$,
    \begin{align*}
        \frac{d}{dx} (f(x) \cdot g(x)) = \frac{dg}{dx}(x)f(x) + \frac{df}{dx}(x) g(x) = g'(x) f(x) + f'(x) g(x)
    \end{align*}
    \item[Chain Rule] For functions $f, g$, 
    \begin{align*}
        \frac{d}{dx}(f(g(x))) = \frac{df}{dx}(g(x))  \cdot \frac{dg}{dx}(x) = f'(g(x)) g'(x)
    \end{align*}
    \item[Log] In this course we use $\log$ to refer to the natural logarithm (also commonly written as $\ln$),
    \begin{align*}
        \frac{d}{dx}(\log(x)) = \frac{1}{x}
    \end{align*}  
    \item[Expoential]
    \begin{align*}
        \frac{d}{dx}(e^x) = e^x
    \end{align*}
    We can generalize this using the chain rule, so that for any constant $a$, we have
    \begin{align*}
        \frac{d}{dx} a^{x} = \log(a) a^x
    \end{align*}
    \item[Inverse differentiation] While the derivative answers how $f$ changes for a small change in $x$, we can similarly ask how much does $x$ change for a small change in $f$, which is the inverse derivative,
    \begin{align*}
        \frac{dx}{df}(x) = \frac{1}{\frac{df}{dx}(x)}
    \end{align*}  
    \item[Differentiation with respect to a function] We can more generally ask, how does a function $f(x)$ change if we increase one component of $f$, say $g(x)$ by a small amount, this yields the derivative of $f(x)$ with respect to $g(x)$,
    \begin{align*}
        \frac{df}{dg}(x) = \frac{df(x)}{dx} \frac{dx}{dg(x)} = \frac{df}{dx}(x) \frac{1}{\frac{dg}{dx}(x)} = \frac{f'(x)}{g'(x)}
    \end{align*}
\end{description}

\subsection*{Multivariable differentiation}
While single variable differentiation tells us how a function changes when there is a single input, we often have functions of multiple variables. Suppose we have a function $f(x_1, x_2, \dots, x_n)$, where $x_1, x_2, \dots, x_n$, are the different arguments that are taken as inputs to the function $f$. We can also write the input to $f$ in \vocab{vector notation}, $\vec{x} = (x_1, x_2, \dots, x_n)$, and the function as $f(\vec{x})$. Throughout this course, we use a bolded letter to denote a vector of values. Formally then, a multivariable function is a function $f: \R^n \to \R$ which takes an $n$ dimensional vector as input, and returns a number as output.\footnote{As a review of notation, recall that $\R \times \R$ is the Cartesian product of $\R$ with itself, which is the set of ordered pairs of real numbers. We denote $\R^n := \R \times \R \times \cdots \times \R$ ($n$ times); that is, $\R^n$ is the set of ordered $n$-tuples of real numbers, or equivalently the set of real vectors in $n$-dimensional space.}

Now, we can examine how to differentiate such a multivariate function. 

\subsubsection*{Partial Differentiation}
While in the single variable case, the derivative tells us how $f$ changes for small change in the input, $x$, in the multivariable, we consider how $f$ changes for a small change to one of the inputs, say $x_k$, while holding all other inputs fixed. Formally, the \vocab{partial derivative} of $f$ with respect to an input $x_k$ at a point $\vec{x} = (x_1, \dots, x_k, \dots, x_n)$,
\begin{align*}
    \frac{\partial f}{\partial x_k}(\vec{x}) = f_{x_k}(\vec{x}) = f_k(x) = \lim_{dx_k \to 0} \frac{f(x_1, \dots, x_k + h, \dots, x_n) - f(x_1, \dots, x_k, \dots, x_n)}{h}
\end{align*}
You may notice that this is very similar to the single variable cases, and indeed partial differentiation is very similar to single variable differentiation, except you treat all other components as fixed. This means that all of the above single differentiation rules also hold for the multivariable case, except replacing the derivative with the partial derivative. 

We have also introduced some new notation for the derivative. $\partials{f}{x_k}$ and $f_{x_k}$ are both notation for the partial derivatives with respect to the input $x_k$. One important piece to note however, is that $x_k$ is just the \emph{name} of the $k$th input to the function, so we can also write $f_k$ to indicate the derivative of $f$ with respect to the $k$th argument. 

We can also take higher order derivatives. Similar to the single variable case, we can differentiate with respect to the same variable twice, which we denote as either $\partials{^2 f}{x_k^2}$, $f_{x_k x_k}$, or $f_{kk}$. We could also first differentiate with respect to $x_k$ first, and then differentiate that result with respect to another variable, say $x_j$. This is known as the \vocab{cross-partial} of $f$ with respect to $x_k$ and $x_j$, and is written,
\begin{align*}
    \frac{\partial^2 f}{\partial x_k \partial x_j} = f_{x_k x_j} = f_{kj}.
\end{align*}
Intuitively, the quantity $f_{x_k x_j}$ represents how an increase in $x_j$ changes the marginal effect that $x_k$ has on $f$.

One important result on cross-partials is \vocab{Young's Theorem}, which states the following:
\begin{theorem*}[Young] % Personal preference for naming theorems; feel free to change this.
    Let $f: \R^n \to \R$ be a smooth function with inputs $x_1, \dots, x_n$, then $\frac{\partial^2 f}{\partial x_k \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_k}$. 
\end{theorem*}
This tells us that for a well-behaved function (in this case we assume smooth with respect to all inputs), then the order we take derivatives in does not matter. 


\subsubsection*{Total differentiation}
While partial differentiation tells us how a function changes for a single input, keeping all other inputs fixed, it is important to remember that with a partial derivatives, all the inputs are really the \emph{names} of inputs that will eventually take on values. In that case, we can consider the following scenario. Suppose we have some multivariable function, $f: \R^n \to \R$, but then we define the single variable function $g: \R \to \R$ as follows:
\begin{align*}
    g(t) = f(t, t, t, \dots, t)
\end{align*}
That is, we are defining $g$ to be the value of $f$ when $x_1 = x_2 = \dots x_n = t$, where $t$ is some value. While we can take partial derivatives of $f$ to see how $f$ changes in response to a single input, in this case, we want to see how $g$ changes in response to all inputs. One way to do this would be to find out the explicit form of $f$ and just plug in $t$ in all the appropropriate places, and then differentiate, but this would require us to know exactly what $f$ is. However, it would be nice if we could see how $g$ changes with respect to $t$ without needing to know how $t$ enters into $f$ explicitly. 

This is the value of the \vocab{total derivative}, which tells us how $g(t) = f(x_1(t), \dots, x_n(t))$ changes with respect to $t$. In this case, we treat each $x_k$ as a single variable function of $t$ which then feeds into the $k$th input of $f$. To find how this changes with respect to $t$, we use the \vocab{multivariable chain rule}, which states,
\begin{align*}
    \frac{dg(t)}{dt} = \frac{df(x_1(t), \dots, x_n(t))}{dt} = \frac{\partial f}{\partial x_1} \frac{d x_1(t)}{dt} + \dots + \frac{\partial f}{\partial x_n} \frac{d x_n(t)}{dt}
\end{align*}
Intuitively, you can think of each term of the sum as how much a small change in $x_k$ affects $f$, multiplied by how a small change in $t$ affects $x_k$. The total affect of a small change to $t$ is all of those individual changes added together. 

\TODO[Add examples]

\subsubsection*{Total vs Partial Derivative}
One common point of confusion is the difference between the total derivative and the partial derivative. After all, the difference between $\frac{\partial f}{\partial x}$ and $\frac{d f}{d x}$ seems to be just one of notation, but they are not in general the same for a multivariable function. 

The partial derivative, $\frac{\partial f}{\partial x}$ tells you how $f$ changes with respect to the variable \emph{named} $x$, while $\frac{df}{dx}$ tells you how $f$ changes with respect to the \emph{value} $x$. This can be particularly confusing if the name of the input is the same as the input value. To see the difference, let's consider the example of the two variable function, 
\begin{align*}
    f(x, y) = x \cdot y^2
\end{align*}
Where the name of the first input is $x$, and the name of the second input is $y$. Now we can consider evaluating $f$ at some value $x$ for both inputs, so $f(x, x)$. What is the partial derivative with respect to $x$ and what is the total derivative?

In this case, the partial derivative with respect to $x$ at the point $x$, $\frac{\partial f}{\partial x}$, is given by differenatiating with respect to the first variable, and then plugging in the values of $x$. To see this, we can first treat it as $f(x, y)$, and differentiate with respect to $x$ holding $y$ fixed, so in general,
\begin{align*}
    \frac{\partial f}{\partial x}(x, y) = y^2
\end{align*}
Next, we plug in the \emph{value} $x$ for both the first and second inputs, so that
\begin{align*}
    \frac{\partial f}{\partial x}(x, x) = x^2
\end{align*}

Compare that to how we take the total derivative. In this case, we first plug in the value of $x$ for both the first and second inputs, so that $f(x, x) = x \cdot x^2 = x^3$, and then differentiate this totally with respect to $x$, so
\begin{align*}
    \frac{df}{dx} = 3x^2
\end{align*}
We can also use the multivariable chain rule.
\begin{align*}
    \frac{df(x, x)}{dx} &= \partials{f}{x} \frac{dx}{dx} + \partials{f}{y} \frac{dy}{dx} \\
    &= (x^2) (1)+ (x) (2x) \\
    &= 3x^2
\end{align*}

In general, you can think of the partial derivative, $\partials{f}{x}$ as differentiating with respect to the variable named $x$ first, and then plugging in a specific value of $x$, while the total derivative is first plugging in a specific value of $x$, and then differentiating with respect to that value. 

\subsection*{Implicit Differentiation}
So far, we have covered how to differentiate functions when we know their explicit form, but one reasonable question is whether or not we can differentiate functions without needing to solve for the function explicitly. This leads us to \vocab{implicit differentiation}, which allows us to differentiate a function while only knowing equality conditions that it satisfies. In some calculus classes, this may have come in the context of solving a related rates problem. 

Consider the area of a circle: $A = \pi r^2$. Suppose we want to find out how the radius must change for a small change in the area of the circle. That is, we want to find $\frac{dr}{dA}$. One way to do this would be to rearrange and solve for $r$ in terms of $A$, and then differentiate,
\begin{align*}
    r &= \sqrt{\frac{A}{\pi}} \\
    \frac{dr}{dA} &= \frac{1}{2\sqrt{\pi A}}
\end{align*}
However, another approach we might take is to differentiate both sides of the equation $A = \pi r^2$ with respect to $A$, treating $r$ as a function of $A$, and then solving for $\frac{dr}{dA}$ when it appears as a result of the chain rule,
\begin{align*}
    \frac{d}{dA} (A) &= \frac{d}{dA} (\pi r^2) \\
    1 &= \pi 2r \frac{dr}{dA} \\
    \frac{1}{2\pi r} &= \frac{dr}{dA}
\end{align*}
This admits an easier solution, and more important, tells us how $r$ changes with respect to $A$ as a function of $r$, without as ever needing to solve for $r$ in terms of $A$ explicitly. Of course, you can verify that if we plug in our above expression of $r$ in terms of $A$ for the derivative, then we obtain the same result. 

However, importantly in this case, only $r$ was a function of the area $A$. Consider a similar problem of finding the volume of a cylinder, $V = \pi r^2 h$. In this case, we would not know how $r$ changes with respect to $V$ because $h$ is also a function of $V$ and we do not know how $h$ changes with respect to $V$. Essentially, the problem is that we have two unknowns but only one equation. To solve explicitly, we would need another equation. However, using implicit differentiation, we can still obtain some useful information. Once again differentiating both sides with respect to $V$ yields and solving for $\frac{dV}{dr}$ yields
\begin{align*}
    \frac{dr}{dV} = \frac{\pi^{-1} - r^2 \frac{dh}{dV}}{h2r}
\end{align*}
Notice here that we can tell how $\frac{dr}{dV}$ is related to each of the other terms. For example, if $\frac{dh}{dV}$ is large, then $\frac{dr}{dV}$ is smaller because the change in volume is mostly accounted for in the height. Similar analyses on economic variables can help us obtain useful insights in terms of how two variables must be related to each other, even when we cannot solve explicitly for the functions or the derivatives. 

\section{Optimization}
Agents in economics are generally assumed to be optimizing an objective function, and derivatives offer us a convenient mathematical tool for optimization of differentiable functions. There are generally two types of optimization functions: unconstrained optimization and constrained optimization, both of which can be solved with differentiation given the approproriate conditions.

\subsection*{Unconstrained Optimization}
The most basic type of optimization is \vocab{unconstrained optimization}, which seeks to optimize some objective function $f$ without any restrictions on what values its arguments can take. We will assume that $f$ is a function of $n$ variables, $x_1, \dots, x_n$, which in vector notation is $\vec{x}$, and that it returns a real number. We will also assume that $f$ is twice continuously differentiable (has two continuous derivatives). 

We want to find some way of characterizing the value $\vec{x}^*$ that maximizes $f$. The problem we want to solve is therefore,
\begin{align*}
    \max_{\vec{x} \in \R^n} f(\vec{x})
\end{align*}
In order for $\vec{x}^*$ to characterize an optimum, there are two conditions that must be satisfied: the first and second order conditions. 

\subsubsection*{First order conditions}
The \vocab{first order conditions} state that in order for $\vec{x}^* = (x_1^*, \dots, x_n^*)$ to be a local optimum, we require that the partial derivative of $f$ with respect to each input $x_k$ to be equal to 0, 
\begin{align*}
    \partials{f}{x_1}(\vec{x}^*) &= 0 \\
    \vdots \\
    \partials{f}{x_k}(\vec{x}^*) &= 0 \\
    \vdots \\
    \partials{f}{x_n}(\vec{x}^*) &= 0
\end{align*}
This is also often known as the \vocab{first derivative test}. This is often written in terms of the \vocab{gradient} of $f$, $\nabla f = (\partials{f}{x_1}, \dots, \partials{f}{x_k}, \dots, \partials{f}{x_n}) = 0$.

To see why this must be the cast, consider the alternatives. Suppose that $\partials{f}{x_k}(\vec{x}^*) > 0$ for some $x_k$. In that case, we could ``nudge'' $x_k^*$ to be slightly larger, and because the partial derivative is positive, the value of the function $f$ will slightly increase, which means that $f(\vec{x}^*)$ is not an optimum. Similarly, if $\partials{f}{x_k}(\vec{x}^*) < 0$, we could decrease $x_k^*$ by a small amount and increase the value of $f$. So, in order for $\vec{x}^*$ to achieve the optimal value of $f$, it must be that the partial derivatives are 0. 

Note that this is a necessary condition, but not a sufficient condition. For example, in the single variable case, the function $f(x) = x^3$ has 0 derivative at $x = 0$, but it is clearly not an optimum 
\todo{Add an image of the graph here}

Moreover, the first order conditions do not distinguish between a maximum and a minimum, and are not sufficient to show that the optimum is global rather than local. In order to verify that $f(\vec{x}^*)$ is a global maximum, an additional condition must be satisfied. 

\todo{Add some examples here}

\subsubsection*{Second order conditions}
The \vocab{second order conditions} (SOC) for a maximum are conditions on the second derivative of $f$. We will focus on the single variable and two-variable case, as higher dimensional second order conditions are beyond the scope of this course.

The \vocab{single variable second order conditions} for a global maximum are given by
\begin{align*}
    \frac{d^2f}{dx^2}(x) < 0 \text{ for all $x$}
\end{align*}
In other words, the $f$ must be a globally concave function. To see why 
this is the case, we can think about what it means for $\frac{d^2f}{dx^2}(x) < 0$. 
\todo{Add some image here of a concave function}
Since $\frac{d^2f}{dx^2}$ is the derivative of $\frac{df}{dx}$, it means that $\frac{df}{dx}(x)$ is decreasing at this point. However, the first order conditions tell us that $\frac{df}{dx}(x) = 0$ at the maximum. Since $\frac{df}{dx}$ is decreasing at this point, the derivative at a slightly greater value of $x$ must be negative, so the value would be lower. Similarly, the derivative at a slightly lower value of $x$ must be positive, which menas that the value can increase. Moreover, because the $\frac{d^2f}{dx^2}(x) < 0$ globally, then it must be that once $\frac{df}{dx}(x) < 0$, it must be negative for all greater values of $x$. 

Similarly, if we are searching for a global minimum, then we require that $\frac{d^2f}{dx^2}(x) > 0$ for all $x$. 

However, the conditions are slightly more complicated for functions of more than one variable. The \vocab{two variable second order conditions} for a global maximum of a function $f(x, y)$ are given by
\begin{align*}
    \frac{\partial^2f}{\partial x^2}(x, y) &< 0 \\ 
    \frac{\partial^2f}{\partial x^2}(x, y) \frac{\partial^2f}{\partial y^2}(x, y) - \left(\frac{\partial^2f}{\partial x \partial y}(x, y)\right)^2 &> 0 \text{ for all $x, y$}
\end{align*}
One thing to notice is that the above inequalities also imply that $\frac{\partial^2f}{\partial y^2} < 0$, so the function must be concave in both variables. However, $\frac{\partial^2f}{\partial y^2} < 0$ and $\frac{\partial^2f}{\partial x^2} < 0$ alone are not sufficient to achieve a local maximum. For a global minimum, we replace the first inequality with $\frac{\partial^2f}{\partial x^2} > 0$. 
\todo{Show an example of SOC being satisfied}

For functions of more than 2 variables, we require that the \vocab{Hessian} matrix of $f$ is negative-semidefinite. We generally will not need to deal with functions of more than 2 variables in this course, and so will not address these conditions here. 

The first and second order conditions are sufficient and necessary conditions for the characterization of a global maximum in an unconstrained maximization problem. However, our problem will often have additional constraints that must be satisfied, and so we can not maximize using any set of inputs.

\subsection*{Constrained Maximization}
Many optimization problems require that you optimize an objective function $f$ while satisfying some constraint, $g(\vec{x}) = c$, where $g$ is a function with the same inputs as $f$ and $c$ is some constant. In economics, this might be a consumer who has to spend $c$ dollars or a firm that is required to produce $c$ units of good. Formally, we write a constrained optimization as
\begin{align*}
    \max_{\vec{x} \in \R^n} f(\vec{x}) \text{ s.t. } g(\vec{x}) = c
\end{align*}

Notice that in this case we only have a single constraint $g(\vec{x}) = c$. In general there are problems with multiple constraints, but we will not address those cases as in this course we only handle cases with a single constraint. 

To solve the constrained optimization problem, we use the \vocab{Lagrangian}, which is defined as,
\begin{align*}
    \Lagr(\vec{x}, \lambda) = f(\vec{x}) - \lambda(g(\vec{x}) - c)
\end{align*}
$\lambda$ is known as the Lagrange Multiplier, and is an added variable to help us handle the constraint. 

To find the constrained maximum, we must satisfy the \vocab{constrained first order conditions}, which require that the partial derivatives of $\Lagr$ with respect to each input is 0,
\begin{align*}
    \partials{\Lagr}{x_1}(\vec{x}^*, \lambda^*) &= 0 \\
    \vdots \\
    \partials{\Lagr}{x_n}(\vec{x}^*, \lambda^*) &= 0 \\
    \partials{\Lagr}{\lambda}(\vec{x}^*, \lambda^*) &= 0
\end{align*}
Notice that we treat the Lagrangian almost as its own objetive function. We can compute the partial derivatives and obtain more direct first order conditions:
\begin{align*}
    \partials{\Lagr}{x_k} = \partials{f}{x_k} - \lambda \partials{g}{x_k} = 0 &\iff \partials{f}{x_k} = \lambda \partials{g}{x_k} \text{ for each $k$}\\
    \partials{\Lagr}{\lambda} = g(x) - c = 0 &\iff g(x) = c
\end{align*}
For students who took a multivariable calculus course that did not use the Lagrangian, this may be a more familiar set of conditions. Namely, $\partials{\Lagr}{\lambda} = 0$ ensures that the constraint is satisfied, while the Lagrange multiplier ensures that $\nabla f = \lambda \nabla g$, which says that the partial derivatives of $f$ and $g$ are a constant proportion of each other.

While this is the first order condition, the full second order conditions for constrained optimization are beyond the scope of this course\todo{Not sure if this is actually true or not}. Instead, it is sufficient to note that if $f$ is a strictly increasing function and $f$ is concave, then it is a sufficient condition (although not necessary) to find a global optimum. 

\todo{Add examples}


\section{Important Properties and Notation}
The differentiation and optimization techniques above will be the foundation of mathematics necessary for this course, there are also some important mathematical properties and notations that we will use throughout this course and will be important to know. We list them here:
\begin{description}
    \item[Convex functions] Convex functions are often known as functions $f$ where the second derivative is negative. However, the real defining property of a convex function is that for any $0 < \alpha < 1$ and any $\vec{x}, \vec{y}$,
    \begin{align*}
        f(\alpha \vec{x} + (1 - \alpha) \vec{y}) \leq \alpha f(\vec{x})) + (1 - \alpha) f(\vec{y})
    \end{align*} 
    
    It can be show that if $f$ is twice differentiable, then $f$ is convex if and only if $\frac{d^2f}{dx^2}(x) < 0$ for any $x$. Graphically, this says that for a convex function, a line segment connecting two points on the function is greater at every point than the function itself. The inequality is reversed for concave functions. A function that is both concave and convex is linear.
    \todo{add image?}
    \item[Monotonic] A monotonic function is any order preserving function. That is, $f$ is a monotonically increasing function if $f(x) < f(y)$ for any $x < y$. 
    \item[Sets] A set is simply a collection (possibly infinite) of mathematical objects. For a set $X$, we write that an element $x$ is in $X$ by $x \in X$. We say that $Y$ is a subset of $X$ if every element of $Y$ is also in $X$, and we write $Y \subset X$.  
    \item[Summation] Suppose we have a sum $x_1 + x_2 + \dots + x_n$. We often write this as $\sum_{i = 1}^n x_i$. For any sequences $x_1, \dots, x_n$ and $y_1, \dots, y_n$ and constants $\alpha, \beta$, we have
    \begin{align*}
        \sum_{i = 1}^n (\alpha x_i + \beta y_i) = \alpha \sum_{i = 1}^n x_i + \beta \sum_{i = 1}^n y_i
    \end{align*} 
    \item[Exponents] Here are some common properties of exponents that should be known,
    \begin{itemize}
        \item $a^{x + y} = a^x a^y$
        \item $(a^x)^y = a^{xy}$
        \item $a^{-x} = \frac{1}{a^{x}}$
        \item $(ab)^x = a^x b^x$
        \item $a^{x/y} = \sqrt[y]{a^x}$
        \item $e^x$ is a monotonically increasing function
    \end{itemize}
    
    \item[Logarithm] We use $\log$ to refer to the natural logarithm, and here are some important properties:
    \begin{itemize}
        \item $e^{\log x} = x$
        \item $\log(e^x) = x$
        \item $\log(1) = 0$
        \item If $0 < x < 1$, $\log x < 0$
        \item If $x > 1$, $\log x > 0$
        \item If $x < 0$, $\log x$ is undefined
        \item $\log(xy) = \log(x) + \log(y)$
        \item $\log(x/y) = \log(x) - \log(y)$
        \item $\log(x^y) = y \log(x)$
        \item $\log(x)$ is a monotonically increasing function
    \end{itemize} 
\end{description}

\section{A Guided Example}

We can finally use the concepts and ideas developed in these first two chapters to work through an example of an economic model. 

\begin{example}
Model how a member of the workforce chooses how many hours to work. What factors influence this choice?
\end{example}

It should not be surprising that this question is one that real economists are often interested in. Understanding this problem might help governments think about policies like tax structures or minimum wages, or it might help firms decide how much to pay their workers. We will present a simple model of this problem and highlight the key modeling steps that apply to a much broader set of modeling problems.

\paragraph{1. Write down the optimization problem.}

The first step is to determine who the decision-making agent is, and what their optimization function is. In this case, the agent is the worker, and we will say their goal is to maximize their utility.\footnote{We will discuss this concept more later, but for now, think of utility as a quantification of someone's level of satisfaction.} 

Next, in order to write down the optimization problem, we need to be able to represent utility as a function of some arguments. It is impossible to write down a model that encapsulates everything a worker might consider in this decision, but also a model that is too simple prevents meaningful insights (e.g. if workers only care about income, they would spend all their time working). 

We will assume that utility is only a function of income ($Y$) and leisure ($L$), so utility is a function $U(Y, L)$. We could assign a functional form like $U(Y, L) = Y + L$, but for the sake of generality, it often helps to start with a general function, think about the characteristics it should have, and only introduce additional structure when it is reasonable and needed.\footnote{Exercise: What functional forms might make sense? We will discuss a few common examples later in this course.} In this case, we can assume that $U$ is increasing in $Y$ and $L$ everywhere, so $\partials{U}{Y}, \partials{U}{L} > 0$ everywhere. This has the interpretation that, all else equal, you would always prefer more income or more leisure over what you currently have. We also assume that $\partials{^2 U}{Y^2}, \partials{^2 U}{L^2} < 0$; this has the interpretation that the marginal utility of income and leisure are both diminishing.

We now need to consider what the choice variables are in this optimization problem. A worker probably does not choose their income directly; rather, we can assume that they choose the number of hours they work per day ($H$), and the rest of the day is devoted to leisure. One approach is to say that $H$ and $L$ are our choice variables. If we assume that $Y = wH$ for some hourly wage $w$ (which is exogenous), we could write down our utility function as $U(wH, L)$. Since we are constrained by the number of hours in a day, we can now write down our constrained optimization problem as 
$$\max_{H, L \geq 0} U(wH, L) \quad \text{s.t.} \quad H + L = 24.$$

It is a useful exercise to solve this maximization problem using the Lagrangian, but a useful trick that will often come in handy in this class is to substitute the constraint directly into the optimization function. That is, we note that $L = 24 - H$, so we can write our utility function as $U(wH, 24 - H)$. Now, we only have one choice variable, $H$, and our constrained optimization problem is now the unconstrained optimization problem
$$\max_{H \in [0, 24]} U(wH, 24 - H).$$

\paragraph{2. Solve the optimization problem.}

We initially wrote our optimization function as $U(Y, L)$, but we can equivalently think of this as a function of our choice variable $H$, where $V(H) \equiv U(wH, 24 - H)$.\footnote{Notation: the $\equiv$ sign means `is equivalent to' and is used when two names refer to the same fundamental quantity by definition, which we might want to differentiate from the cases where the $=$ sign simply refers to two different fundamental quantities that are equal.} We assume that $U(Y, L)$ is twice continuously differentiable, which implies $V(H)$ is twice continuously differentiable as well. 

We want to solve for the optimal solution $H^*$ for the choice variable (as a function of the exogenous variable $w$). If there is an \vocab{internal solution} $H^* \in (0, 24)$ that maximizes the optimization function (as opposed to the solution being $H^* = 0$ or $H^* = 24$, then it must satisfy the first-order condition
$$\frac{d}{dH}V(H^*) = 0.$$
To solve, we substitute our definition of $V(H)$ to get
$$\frac{d}{dH} U(wH^*, 24 - H^*) = 0.$$
We now apply the multivariate chain rule to get
$$w \partials{U}{Y} - \partials{U}{L} = 0,$$
or if you prefer,
$$\boxed{w\partials{U}{Y} = \partials{U}{L}.}\footnote{We suppress the arguments of $\partials{U}{Y}$ and $\partials{U}{L}$ for clarity, but remember that they are functions of $H$.}$$

This is our solution! You might have been expecting something of the form
$$H^* = \text{stuff}.$$
This type of solution would be called an \vocab{explicit solution} for $H^*$. The solution we gave instead is called an \vocab{implicit solution.} It is very important to note that this solution is just as acceptable. Recall that $\partials{U}{Y}$ and $\partials{U}{L}$ are functions of $H$; thus, the equation we gave pins down the value of $H^*$ that gives us our optimum. Intuitively, this equation tells us that you should work until your marginal utility of leisure and income are equal; this is the point where if you had an extra second in your day, you would be indifferent between spending it on work and spending it on leisure.

\paragraph{3. Check your solution.}

There is some value of $H^*$ that satisfies the implicit solution we gave, but how do we know that it actually maximizes the optimization problem we initially gave? There are two important checks we need to perform.

First, how do we know that the solution for the FOC is a maximum and not a minimum? We need to check the second-order condition (SOC)
$$\frac{d^2}{dH^2}V(H^*) < 0.$$
If we assume that $V$ is concave in $H$, then this condition is automatically satisfied. If instead we needed to compute this, we would write down what we had before
\begin{align*}
V'(H) &=\frac{d}{d H} U(w H, 24-H) \\
&=w \frac{\partial U}{\partial Y}(w H, 24-H)-\frac{\partial U}{\partial L}(w H, 24-H) \\
&=w U_{Y}(w H, 24-H)-U_{L}(w H, 24-H).\footnote{Notation: U_{Y} \equiv \frac{\partial U}{\partial Y}, U_{L} \equiv \frac{\partial U}{\partial L}, U_{Y L} \equiv \frac{\partial^{2} U}{\partial Y \partial L}.}
\end{align*}
We would then differentiate again to get
\begin{align*}
V''(H) &=w \frac{d}{d H} U_{Y}(w H, 24-H)-\frac{d}{d H} U_{L}(w H, 24-H) \\
&=w^{2} U_{Y Y}-w U_{Y L}-w U_{L Y}+U_{L L} \\
&=w^{2} U_{Y Y}-2 w U_{Y L}+U_{L L}.
\end{align*}
Our SOC is satisfied when this value is negative at $H^*$.

Second, we need to check for \vocab{corner solutions}. These are potential solutions where the optimal value of the choice variable is on the boundary of the constraints we set for it. In our example, our implicit solution pins down some real value for $H^*$, but what if it were negative or greater than 24? Alternatively, what if our solution for $H^*$ was only a local maximum, but the global maximum in our interval were actually on the boundaries of the interval? Thus, we should check that $H^* \in [0, 24]$, and we should plug in $H = 0$ and $H = 24$ into our optimization function $V(H)$ to check that their values are less than $V(H^*)$. 

\paragraph{4. Take comparative statics.}

Recall that comparative statics describe how the optimal values of the choice variables change when the exogenous variables change; at the end of the day, this quantity is what we are really interested in and is useful in policy discussions. Our only exogenous variable is $w$, and we are interested in finding $\partials{H^*}{w}$ (recall that $H^*$ is a function of the exogenous variables). Our solution for $H^*$, which we can think of as $H^*(w)$, from our FOCs was 
$$w\partials{U}{Y} = \partials{U}{L}.$$
If we include the arguments of $\partials{U}{Y}$ and $\partials{U}{L}$, we can write this as
$$w U_{Y}\left(w H^{*}(w), 24-H^{*}(w)\right)=U_{L}\left(w H^{*}(w), 24-H^{*}(w)\right).$$

In order to get $\partials{H^*}{w}$ out of this, we use the \vocab{Implicit Function Theorem} to take the derivative of both sides of the equation, yielding 
$$\frac{d}{d w}\left[w U_{Y}\left(w H^{*}(w), 24-H^{*}(w)\right)\right]=\frac{d}{d w} U_{L}\left(w H^{*}(w), 24-H^{*}(w)\right).$$
We use the chain rule and the product rule to get (note that we suppress arguments of functions again for clarity)
$$U_{Y}+w U_{Y Y} H^{*}+w\left(U_{Y Y} w-U_{Y L}\right) \frac{\partial H^{*}}{\partial w} = U_{L Y} H^{*}+\left(U_{L Y} w-U_{L L}\right) \frac{\partial H^{*}}{\partial w}.$$
We can rearrange to solve for 
$$\boxed{\frac{\partial H^{*}}{\partial w}=\frac{U_{Y}+w H^{*} U_{Y Y}-H^{*} U_{Y L}}{-\left(w^{2} U_{Y Y}-2 w U_{Y L}+U_{L L}\right)}.}$$

Note that we got this without solving for $H^*(w)$ explicitly! The naive approach would have been to find the explicit solution and then manually take its derivative. Here, we see that using an implicit solution and applying the Implicit Function Theorem leads to a much faster solution.

\paragraph{5. Interpret your results.}

What we really care about is the sign of $\partials{H^*}{w}$. If wages increase, do people work more or less? The denominator of our solution must be positive, since it is exactly the expression from our SOC. The sign of the numerator depends on the magnitudes of the different terms. We said in our initial assumptions that $U_Y$ is positive and that $U_{YY}$ is negative. What about the sign of $U_{YL}$? Maybe it's positive: if you are richer, then maybe the marginal utility of leisure is higher, since you can afford more expensive hobbies. Maybe it's negative: if you are richer, maybe you lose appreciation for the everyday moments in life, so the marginal utility of leisure is actually lower. How might we resolve this question with data?

